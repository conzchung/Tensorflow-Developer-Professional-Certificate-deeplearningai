{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "lbFmQdsZs5eW",
    "outputId": "18646587-a2d1-4e16-ef5d-5348c485d367"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1xJZ5glPPCRz",
    "outputId": "b567fffe-3176-4bd3-d8e0-3f0aafd4fe7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-14 10:13:41--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.193.128, 2607:f8b0:4001:c05::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.193.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87910968 (84M) [application/x-hdf]\n",
      "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
      "\n",
      "/tmp/inception_v3_w 100%[===================>]  83.84M  81.8MB/s    in 1.0s    \n",
      "\n",
      "2020-02-14 10:13:42 (81.8 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Download the inception v3 weights\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150,150,3),\n",
    "                                include_top = False,\n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False\n",
    "  \n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "CFsUlwdfs_wg",
    "outputId": "0dca7db0-fe75-4e30-a8a0-a588e45c604f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.999):\n",
    "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BMXb913pbvFg",
    "outputId": "e1bb174b-cc0a-41c2-db20-02840fa202bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "HrnL_IQ8knWA",
    "outputId": "8b92f4f9-7f45-4549-ac11-0f87d4766d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-02-14 10:13:52--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 2607:f8b0:4001:c07::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 149574867 (143M) [application/zip]\n",
      "Saving to: ‘/tmp/horse-or-human.zip’\n",
      "\n",
      "/tmp/horse-or-human 100%[===================>] 142.65M   116MB/s    in 1.2s    \n",
      "\n",
      "2020-02-14 10:13:53 (116 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
      "\n",
      "--2020-02-14 10:13:54--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 2607:f8b0:4001:c18::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11480187 (11M) [application/zip]\n",
      "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
      "\n",
      "/tmp/validation-hor 100%[===================>]  10.95M  64.7MB/s    in 0.2s    \n",
      "\n",
      "2020-02-14 10:13:54 (64.7 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the Horse or Human dataset\n",
    "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
    "\n",
    "# Get the Horse or Human Validation dataset\n",
    "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
    "  \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = '//tmp/horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = '//tmp/validation-horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "y9okX7_ovskI",
    "outputId": "33706bde-bc46-461f-d0bb-044dbffef9a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "train_horses_dir = '/tmp/training/horses'\n",
    "train_humans_dir = '/tmp/training/humans'\n",
    "validation_horses_dir = '/tmp/validation/horses'\n",
    "validation_humans_dir = '/tmp/validation/humans'\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)\n",
    "train_humans_fnames = os.listdir(train_humans_dir)\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "O4s8HckqGlnb",
    "outputId": "d86ad0ad-25e4-44c3-998e-6d698c708c03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 16,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (150,150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                    batch_size = 8,\n",
    "                                                    class_mode = 'binary',\n",
    "                                                    target_size = (150,150))\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Blhq2MAUeyGA",
    "outputId": "1af7ba20-9fb0-4c44-d560-3ba11e109230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "64/64 - 17s - loss: 0.2415 - acc: 0.9011 - val_loss: 0.0231 - val_acc: 0.9922\n",
      "Epoch 2/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0914 - acc: 0.9703 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0764 - acc: 0.9713 - val_loss: 0.0516 - val_acc: 0.9844\n",
      "Epoch 4/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0563 - acc: 0.9832 - val_loss: 0.0080 - val_acc: 0.9961\n",
      "Epoch 5/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.1007 - acc: 0.9763 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0358 - acc: 0.9881 - val_loss: 0.0135 - val_acc: 0.9961\n",
      "Epoch 7/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0670 - acc: 0.9822 - val_loss: 0.0383 - val_acc: 0.9961\n",
      "Epoch 8/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0507 - acc: 0.9822 - val_loss: 0.0478 - val_acc: 0.9922\n",
      "Epoch 9/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0304 - acc: 0.9911 - val_loss: 0.0913 - val_acc: 0.9844\n",
      "Epoch 10/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0518 - acc: 0.9792 - val_loss: 0.1865 - val_acc: 0.9648\n",
      "Epoch 11/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0313 - acc: 0.9881 - val_loss: 0.5484 - val_acc: 0.9453\n",
      "Epoch 12/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0412 - acc: 0.9862 - val_loss: 0.3669 - val_acc: 0.9570\n",
      "Epoch 13/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0469 - acc: 0.9832 - val_loss: 0.2572 - val_acc: 0.9727\n",
      "Epoch 14/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0242 - acc: 0.9931 - val_loss: 0.6721 - val_acc: 0.9375\n",
      "Epoch 15/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0645 - acc: 0.9862 - val_loss: 0.2195 - val_acc: 0.9727\n",
      "Epoch 16/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0346 - acc: 0.9871 - val_loss: 0.3113 - val_acc: 0.9648\n",
      "Epoch 17/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0500 - acc: 0.9901 - val_loss: 0.5190 - val_acc: 0.9570\n",
      "Epoch 18/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0456 - acc: 0.9873 - val_loss: 0.0949 - val_acc: 0.9883\n",
      "Epoch 19/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0549 - acc: 0.9870 - val_loss: 0.2813 - val_acc: 0.9648\n",
      "Epoch 20/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0345 - acc: 0.9902 - val_loss: 0.5490 - val_acc: 0.9492\n",
      "Epoch 21/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0763 - acc: 0.9870 - val_loss: 0.1621 - val_acc: 0.9805\n",
      "Epoch 22/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0266 - acc: 0.9932 - val_loss: 0.4398 - val_acc: 0.9531\n",
      "Epoch 23/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0531 - acc: 0.9900 - val_loss: 0.1970 - val_acc: 0.9766\n",
      "Epoch 24/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0102 - acc: 0.9931 - val_loss: 0.1988 - val_acc: 0.9766\n",
      "Epoch 25/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0479 - acc: 0.9883 - val_loss: 0.0945 - val_acc: 0.9883\n",
      "Epoch 26/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0075 - acc: 0.9980 - val_loss: 0.1391 - val_acc: 0.9844\n",
      "Epoch 27/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0261 - acc: 0.9900 - val_loss: 0.1171 - val_acc: 0.9844\n",
      "Epoch 28/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0469 - acc: 0.9911 - val_loss: 0.1904 - val_acc: 0.9766\n",
      "Epoch 29/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0183 - acc: 0.9960 - val_loss: 0.7555 - val_acc: 0.9531\n",
      "Epoch 30/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0205 - acc: 0.9951 - val_loss: 0.9794 - val_acc: 0.9492\n",
      "Epoch 31/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0260 - acc: 0.9970 - val_loss: 0.2864 - val_acc: 0.9727\n",
      "Epoch 32/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0147 - acc: 0.9941 - val_loss: 0.7885 - val_acc: 0.9492\n",
      "Epoch 33/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0092 - acc: 0.9980 - val_loss: 0.9211 - val_acc: 0.9492\n",
      "Epoch 34/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0180 - acc: 0.9921 - val_loss: 0.6827 - val_acc: 0.9492\n",
      "Epoch 35/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0198 - acc: 0.9911 - val_loss: 0.6646 - val_acc: 0.9531\n",
      "Epoch 36/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0426 - acc: 0.9930 - val_loss: 0.7379 - val_acc: 0.9492\n",
      "Epoch 37/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0188 - acc: 0.9951 - val_loss: 0.5137 - val_acc: 0.9570\n",
      "Epoch 38/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0140 - acc: 0.9940 - val_loss: 0.6226 - val_acc: 0.9492\n",
      "Epoch 39/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0321 - acc: 0.9951 - val_loss: 0.5235 - val_acc: 0.9570\n",
      "Epoch 40/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0162 - acc: 0.9940 - val_loss: 0.2774 - val_acc: 0.9766\n",
      "Epoch 41/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0039 - acc: 0.9980 - val_loss: 0.6430 - val_acc: 0.9492\n",
      "Epoch 42/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0295 - acc: 0.9930 - val_loss: 0.6326 - val_acc: 0.9492\n",
      "Epoch 43/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0136 - acc: 0.9951 - val_loss: 0.5485 - val_acc: 0.9531\n",
      "Epoch 44/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0205 - acc: 0.9951 - val_loss: 0.3354 - val_acc: 0.9727\n",
      "Epoch 45/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0043 - acc: 0.9980 - val_loss: 0.3670 - val_acc: 0.9727\n",
      "Epoch 46/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0184 - acc: 0.9951 - val_loss: 0.6246 - val_acc: 0.9570\n",
      "Epoch 47/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0223 - acc: 0.9941 - val_loss: 0.7181 - val_acc: 0.9531\n",
      "Epoch 48/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0438 - acc: 0.9901 - val_loss: 0.9065 - val_acc: 0.9492\n",
      "Epoch 49/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0146 - acc: 0.9940 - val_loss: 0.9320 - val_acc: 0.9453\n",
      "Epoch 50/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0081 - acc: 0.9960 - val_loss: 0.6809 - val_acc: 0.9531\n",
      "Epoch 51/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0279 - acc: 0.9951 - val_loss: 0.9977 - val_acc: 0.9492\n",
      "Epoch 52/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0061 - acc: 0.9971 - val_loss: 0.5089 - val_acc: 0.9688\n",
      "Epoch 53/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0216 - acc: 0.9931 - val_loss: 0.5029 - val_acc: 0.9648\n",
      "Epoch 54/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0134 - acc: 0.9951 - val_loss: 0.2999 - val_acc: 0.9727\n",
      "Epoch 55/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0226 - acc: 0.9920 - val_loss: 0.6638 - val_acc: 0.9570\n",
      "Epoch 56/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0102 - acc: 0.9971 - val_loss: 0.7875 - val_acc: 0.9492\n",
      "Epoch 57/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0777 - acc: 0.9931 - val_loss: 0.5225 - val_acc: 0.9609\n",
      "Epoch 58/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0154 - acc: 0.9980 - val_loss: 0.5225 - val_acc: 0.9609\n",
      "Epoch 59/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0297 - acc: 0.9941 - val_loss: 0.3788 - val_acc: 0.9688\n",
      "Epoch 60/100\n",
      "Epoch 1/100\n",
      "64/64 - 11s - loss: 0.0083 - acc: 0.9980 - val_loss: 0.3525 - val_acc: 0.9727\n",
      "Epoch 61/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0083 - acc: 0.9971 - val_loss: 0.1955 - val_acc: 0.9883\n",
      "Epoch 62/100\n",
      "Epoch 1/100\n",
      "64/64 - 12s - loss: 0.0140 - acc: 0.9970 - val_loss: 0.2336 - val_acc: 0.9805\n",
      "Epoch 63/100\n",
      "Epoch 1/100\n",
      "\n",
      "Reached 99.9% accuracy so cancelling training!\n",
      "64/64 - 11s - loss: 0.0023 - acc: 0.9990 - val_loss: 0.1999 - val_acc: 0.9844\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 99.9% accuracy\n",
    "# (It should take less than 100 epochs)\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit_generator(train_generator,\n",
    "                              validation_data = validation_generator,\n",
    "                              steps_per_epoch = 64,\n",
    "                              epochs = 3,\n",
    "                              validation_steps = 32,\n",
    "                              verbose = 2,\n",
    "                              callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL",
    "outputId": "a6eb8ec1-e97d-40f0-b22d-665e312f7706"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r_vkmF5VMAJu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
